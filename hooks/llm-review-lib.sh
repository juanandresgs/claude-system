#!/usr/bin/env bash
# LLM-as-Judge shared library for command safety review.
# Source this file from llm-review.sh:
#   source "$(dirname "$0")/llm-review-lib.sh"
#
# Provides:
#   call_gemini <cmd> <cwd> <branch> <plan> [prior]  - Calls Gemini API
#   call_openai <cmd> <cwd> <branch> <plan> [prior]  - Calls OpenAI API
#   lookup_cache <hash> <file>                         - Read cached verdict
#   write_cache <hash> <verdict> <reason> <file>       - Append to cache
#   emit_verdict <verdict> <reason>                    - Output allow/advisory JSON
#   emit_deny <reason>                                 - Output deny JSON
#   emit_advisory <message>                            - Output advisory JSON
#   get_plan_excerpt <root>                            - Extract plan intent + phase
#
# @decision DEC-LLMREVIEW-001
# @title External LLM command safety review with dual-provider consensus
# @status accepted
# @rationale Static pattern matching (auto-review.sh) cannot handle compound
#   commands, custom scripts, or commands with embedded code. An external LLM
#   reviewer understands command semantics. Using a different provider (Gemini)
#   gives genuine independence from the Claude session. Deny requires
#   cross-provider consensus (Gemini + OpenAI) â€” a single model cannot veto.

# --- Configuration ---
LLM_REVIEW_GEMINI_MODEL="${LLM_REVIEW_GEMINI_MODEL:-gemini-3-pro-preview}"
LLM_REVIEW_OPENAI_MODEL="${LLM_REVIEW_OPENAI_MODEL:-gpt-5.3-codex}"

# --- System prompt (shared by both providers) ---
LLM_REVIEW_SYSTEM_PROMPT='You are a command safety reviewer for a software development environment.
Analyze the bash command. Look INSIDE string arguments for hidden execution
(python -c, bash -c, eval, node -e). Consider: file deletion, network
exfiltration, privilege escalation, data destruction.
Respond with ONLY JSON: {"verdict":"safe|unsafe|misaligned",
"confidence":0.0-1.0,"reason":"one sentence",
"problematic_part":"specific dangerous substring or empty"}'

# --- API Callers ---

# Call Gemini 3 Pro generateContent API.
# Args: <command> <cwd> <branch> <plan_excerpt> [prior_review]
# Outputs: raw JSON response text from model (verdict JSON)
# Returns: 0 on success, 1 on failure
call_gemini() {
    local cmd="$1" cwd="$2" branch="$3" plan="$4" prior="${5:-}"

    local user_msg="Command: $cmd
Working directory: $cwd
Git branch: $branch
Project intent: $plan"
    [[ -n "$prior" ]] && user_msg="$user_msg
Prior review (another model flagged this as unsafe): $prior"

    local full_prompt="$LLM_REVIEW_SYSTEM_PROMPT

$user_msg"

    # Escape for JSON using jq
    local escaped_prompt
    escaped_prompt=$(printf '%s' "$full_prompt" | jq -Rs .)

    local response
    response=$(curl -sS --max-time 3 \
        -H "x-goog-api-key: $GEMINI_API_KEY" \
        -H "Content-Type: application/json" \
        "https://generativelanguage.googleapis.com/v1beta/models/${LLM_REVIEW_GEMINI_MODEL}:generateContent" \
        -d "{\"contents\":[{\"parts\":[{\"text\":${escaped_prompt}}]}],\"generationConfig\":{\"maxOutputTokens\":256,\"temperature\":0}}" \
        2>/dev/null) || return 1

    # Extract text from response
    local text
    text=$(echo "$response" | jq -r '.candidates[0].content.parts[0].text // empty' 2>/dev/null) || return 1
    [[ -z "$text" ]] && return 1

    echo "$text"
    return 0
}

# Call OpenAI Chat Completions API.
# Args: <command> <cwd> <branch> <plan_excerpt> [prior_review]
# Outputs: raw JSON response text from model (verdict JSON)
# Returns: 0 on success, 1 on failure
call_openai() {
    local cmd="$1" cwd="$2" branch="$3" plan="$4" prior="${5:-}"

    local user_msg="Command: $cmd
Working directory: $cwd
Git branch: $branch
Project intent: $plan"
    [[ -n "$prior" ]] && user_msg="$user_msg
Prior review (another model flagged this as unsafe): $prior"

    # Escape for JSON
    local escaped_system escaped_user
    escaped_system=$(printf '%s' "$LLM_REVIEW_SYSTEM_PROMPT" | jq -Rs .)
    escaped_user=$(printf '%s' "$user_msg" | jq -Rs .)

    local response
    response=$(curl -sS --max-time 5 \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -H "Content-Type: application/json" \
        "https://api.openai.com/v1/chat/completions" \
        -d "{\"model\":\"${LLM_REVIEW_OPENAI_MODEL}\",\"messages\":[{\"role\":\"system\",\"content\":${escaped_system}},{\"role\":\"user\",\"content\":${escaped_user}}],\"max_tokens\":256,\"temperature\":0}" \
        2>/dev/null) || return 1

    local text
    text=$(echo "$response" | jq -r '.choices[0].message.content // empty' 2>/dev/null) || return 1
    [[ -z "$text" ]] && return 1

    echo "$text"
    return 0
}

# --- Cache Operations ---

# Look up a cached verdict by command hash.
# Args: <sha256_hash> <cache_file>
# Outputs: "verdict|reason" if found
# Returns: 0 if hit, 1 if miss
lookup_cache() {
    local hash="$1" cache_file="$2"
    [[ ! -f "$cache_file" ]] && return 1

    local line
    line=$(grep "^${hash}|" "$cache_file" 2>/dev/null | tail -1) || return 1
    [[ -z "$line" ]] && return 1

    # Format: hash|verdict|reason|epoch
    local verdict reason
    verdict=$(echo "$line" | cut -d'|' -f2)
    reason=$(echo "$line" | cut -d'|' -f3)
    echo "${verdict}|${reason}"
    return 0
}

# Write a cache entry.
# Args: <sha256_hash> <verdict> <reason> <cache_file>
write_cache() {
    local hash="$1" verdict="$2" reason="$3" cache_file="$4"
    local epoch
    epoch=$(date +%s)
    # Sanitize reason: strip pipes and newlines
    reason=$(echo "$reason" | tr '|' '-' | tr '\n' ' ' | sed 's/ *$//')
    echo "${hash}|${verdict}|${reason}|${epoch}" >> "$cache_file"
}

# --- Verdict Emitters ---

# Emit an allow verdict (auto-approve).
# Args: <reason>
emit_allow() {
    local reason="$1"
    # Escape reason for JSON
    local escaped
    escaped=$(printf '%s' "$reason" | jq -Rs . | sed 's/^"//;s/"$//')
    cat <<EOF
{
  "hookSpecificOutput": {
    "hookEventName": "PreToolUse",
    "permissionDecision": "allow",
    "permissionDecisionReason": "llm-review: $escaped"
  }
}
EOF
}

# Emit a deny verdict (block command).
# Args: <reason>
emit_deny() {
    local reason="$1"
    local escaped
    escaped=$(printf '%s' "$reason" | jq -Rs . | sed 's/^"//;s/"$//')
    cat <<EOF
{
  "hookSpecificOutput": {
    "hookEventName": "PreToolUse",
    "permissionDecision": "deny",
    "permissionDecisionReason": "llm-review: $escaped"
  }
}
EOF
}

# Emit an advisory (no blocking, context injection only).
# Args: <message>
emit_advisory() {
    local message="$1"
    local escaped
    escaped=$(printf '%s' "$message" | jq -Rs . | sed 's/^"//;s/"$//')
    cat <<EOF
{
  "hookSpecificOutput": {
    "hookEventName": "PreToolUse",
    "additionalContext": "llm-review: $escaped"
  }
}
EOF
}

# --- Plan Excerpt ---

# Extract a compact plan excerpt for LLM context.
# Args: <project_root>
# Outputs: truncated plan excerpt (max ~1500 chars)
get_plan_excerpt() {
    local root="$1"
    local plan_file="$root/MASTER_PLAN.md"

    if [[ ! -f "$plan_file" ]]; then
        echo "No project plan found."
        return
    fi

    # First 20 lines for intent/vision
    local header
    header=$(head -20 "$plan_file" 2>/dev/null || echo "")

    # Find current in-progress phase
    local current_phase
    current_phase=$(grep -B5 'Status:\*\*\s*in-progress' "$plan_file" 2>/dev/null \
        | grep -E '^\#\#\s+Phase' | head -1 || echo "")

    local excerpt="$header"
    [[ -n "$current_phase" ]] && excerpt="$excerpt
Active phase: $current_phase"

    # Truncate to ~1500 chars
    echo "$excerpt" | head -c 1500
}

# --- Response Parser ---

# Parse LLM response text into verdict components.
# Args: <response_text>
# Sets globals: PARSED_VERDICT, PARSED_CONFIDENCE, PARSED_REASON, PARSED_PROBLEMATIC
# Returns: 0 on success, 1 on parse failure
parse_llm_response() {
    local text="$1"

    # Extract JSON from response (may be wrapped in markdown code blocks)
    local json
    json=$(echo "$text" | sed -n 's/.*\({.*}\).*/\1/p' | head -1)
    [[ -z "$json" ]] && return 1

    PARSED_VERDICT=$(echo "$json" | jq -r '.verdict // empty' 2>/dev/null) || return 1
    PARSED_CONFIDENCE=$(echo "$json" | jq -r '.confidence // "0"' 2>/dev/null) || PARSED_CONFIDENCE="0"
    PARSED_REASON=$(echo "$json" | jq -r '.reason // "no reason given"' 2>/dev/null) || PARSED_REASON="no reason given"
    PARSED_PROBLEMATIC=$(echo "$json" | jq -r '.problematic_part // ""' 2>/dev/null) || PARSED_PROBLEMATIC=""

    # Validate verdict value
    case "$PARSED_VERDICT" in
        safe|unsafe|misaligned) return 0 ;;
        *) return 1 ;;
    esac
}

# Export for subshells
export LLM_REVIEW_SYSTEM_PROMPT LLM_REVIEW_GEMINI_MODEL LLM_REVIEW_OPENAI_MODEL
export -f call_gemini call_openai lookup_cache write_cache emit_allow emit_deny emit_advisory get_plan_excerpt parse_llm_response
